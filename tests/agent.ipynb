{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9491843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\miniproject\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "from client.object_detection import DetectionClient\n",
    "from client.segmentation import SegmentationClient\n",
    "from client.generation import ImageGenerationClient # generation.pyì— ìˆë‹¤ê³  ê°€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f65d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKEND_URL = \"http://157.66.255.80:14252\"\n",
    "VLLM_BASE_URL=BACKEND_URL + \"/vllm/v1\"\n",
    "IMAGE_BASE_URL=BACKEND_URL + \"/image\"\n",
    "\n",
    "detection_client = DetectionClient(base_url=IMAGE_BASE_URL)\n",
    "segmentation_client = SegmentationClient(base_url=IMAGE_BASE_URL)\n",
    "inpainting_client = ImageGenerationClient(base_url=IMAGE_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a89b71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def detect_object(image_path: str, object_name: str) -> str:\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ì—ì„œ íŠ¹ì • ê°ì²´('object_name')ì˜ ìœ„ì¹˜ë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    ì…ë ¥: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ('image_path'), ì°¾ì„ ê°ì²´ì˜ ì´ë¦„('object_name').\n",
    "    ì¶œë ¥: ì°¾ì€ ê°ì²´ì˜ bounding box ì¢Œí‘œë¥¼ ë‹´ì€ JSON ë¬¸ìì—´.\n",
    "    \"\"\"\n",
    "    print(f\"--- 1. [ì‹¤ì œ API í˜¸ì¶œ] ê°ì²´ íƒì§€ ì‹¤í–‰: {object_name} ---\")\n",
    "    \n",
    "    try:\n",
    "        # 1. ì´ë¯¸ì§€ íŒŒì¼ì„ ì—´ì–´ì„œ ë°”ì´íŠ¸(bytes) ë°ì´í„°ë¡œ ì½ìŠµë‹ˆë‹¤.\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            image_bytes = image_file.read()\n",
    "\n",
    "        # 2. detection_client.detect ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "        #    ì´ë•Œ, ì´ íŒŒì¼(DetectionClient)ì˜ ê·œì¹™ì— ë§ì¶° ì¸ìë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "        result_obj = detection_client.detect(\n",
    "            image=image_bytes,                # ì´ë¯¸ì§€ ë°ì´í„°\n",
    "            text=[object_name],               # <<<--- 1. ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ ì „ë‹¬!\n",
    "            threshold=0.25                    # ê¸°ë³¸ê°’ ì‚¬ìš©\n",
    "        )\n",
    "\n",
    "        # 3. ë°±ì—”ë“œë¡œë¶€í„° ë°›ì€ ê²°ê³¼ ê°ì²´(DetectorOutput)ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ í›„,\n",
    "        #    JSON ë¬¸ìì—´ë¡œ ë§Œë“¤ì–´ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "        return result_obj.model_dump_json()\n",
    "\n",
    "    except Exception as e:\n",
    "        # API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´, ì—ì´ì „íŠ¸ì—ê²Œ ì˜¤ë¥˜ ë‚´ìš©ì„ ì•Œë ¤ì¤ë‹ˆë‹¤.\n",
    "        return f\"Detect API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1033453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def segment_object(image_path: str, bounding_box_json: str) -> str:\n",
    "    \"\"\"ì´ë¯¸ì§€ì—ì„œ ì£¼ì–´ì§„ ì¢Œí‘œì— í•´ë‹¹í•˜ëŠ” ì˜ì—­ì˜ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ê³  ë§ˆìŠ¤í¬ê°€ ì €ì¥ëœ ê²½ë¡œë¥¼ ë¦¬í„´í•©ë‹ˆë‹¤.\"\"\"\n",
    "    print(f\"\\n--- 2. [ë„êµ¬ ì‹¤í–‰] segment_object ---\")\n",
    "    print(f\"   - ì…ë ¥: image_path='{image_path}', bounding_box_json='{bounding_box_json}'\")\n",
    "\n",
    "    try:\n",
    "        # 1. json.loads()ë¥¼ í†µí•´ ë¬¸ìì—´ì„ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸(float í¬í•¨)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "        box_data_float = json.loads(bounding_box_json)\n",
    "        \n",
    "        # 2. ë¦¬ìŠ¤íŠ¸ì˜ ëª¨ë“  í•­ëª©ì„ ì •ìˆ˜(integer)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "        #    ì˜ˆ: [144.73, 255.1] -> [144, 255]\n",
    "        # <<<--- ì—¬ê¸°ê°€ ê°€ì¥ ì¤‘ìš”í•œ ìˆ˜ì • í¬ì¸íŠ¸! ---\n",
    "        box_data_int = [int(coord) for coord in box_data_float]\n",
    "\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            image_bytes = image_file.read()\n",
    "        \n",
    "        # 3. API ìš”ì²­ ì‹œ ì •ìˆ˜ë¡œ ë³€í™˜ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "        print(f\"   - API ìš”ì²­: box={box_data_int} ë¥¼ /segment/box ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³´ëƒ…ë‹ˆë‹¤.\")\n",
    "        \n",
    "        segmentation_result = segmentation_client.segment_box(\n",
    "            image=image_bytes, \n",
    "            box=box_data_int  # ì •ìˆ˜í˜• ë¦¬ìŠ¤íŠ¸ë¥¼ ì „ë‹¬\n",
    "        )\n",
    "        \n",
    "        # (ì´í•˜ ì½”ë“œëŠ” ë™ì¼)\n",
    "        mask = segmentation_result.extract_masks()[0]\n",
    "        mask_path = \"mask_result.png\"\n",
    "        mask.save(mask_path)\n",
    "            \n",
    "        print(f\"   - API ì‘ë‹µ (ì„±ê³µ): ë§ˆìŠ¤í¬ íŒŒì¼ ì €ì¥ ì™„ë£Œ -> '{mask_path}'\")\n",
    "        return mask_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   - API í˜¸ì¶œ ì˜¤ë¥˜: {e}\")\n",
    "        return f\"Segment API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec87751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def inpaint_image(image_path: str, mask_path: str, prompt: str) -> str:\n",
    "    \"\"\"ì›ë³¸ ì´ë¯¸ì§€ì˜ ë§ˆìŠ¤í¬ ì˜ì—­ì„ ì£¼ì–´ì§„ í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ ìƒˆë¡­ê²Œ ì±„ìš°ê³  ì €ì¥ëœ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë¦¬í„´í•©ë‹ˆë‹¤.\"\"\"\n",
    "    print(f\"\\n--- 3. [ë„êµ¬ ì‹¤í–‰] inpaint_image ---\")\n",
    "    print(f\"   - ì…ë ¥: image_path='{image_path}', mask_path='{mask_path}', prompt='{prompt}'\")\n",
    "\n",
    "    try:\n",
    "        # 1. ì›ë³¸ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ê°ê° ì—´ì–´ì„œ ë°”ì´íŠ¸ ë°ì´í„°ë¡œ ì½ìŠµë‹ˆë‹¤.\n",
    "        with open(image_path, \"rb\") as image_file, open(mask_path, \"rb\") as mask_file:\n",
    "            image_bytes = image_file.read()\n",
    "            mask_bytes = mask_file.read()\n",
    "            \n",
    "        print(f\"   - API ìš”ì²­: prompt='{prompt}' ë¥¼ /generate/inpaint ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³´ëƒ…ë‹ˆë‹¤.\")\n",
    "        \n",
    "        # 2. inpainting_clientì˜ 'inpaint' ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "        #    ì´ë•Œ, Clientì˜ ê·œì¹™ì— ë§ëŠ” 'control_image', 'control_mask' ë§¤ê°œë³€ìˆ˜ ì´ë¦„ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "        # <<<--- ì—¬ê¸°ê°€ ê°€ì¥ ì¤‘ìš”í•œ ìˆ˜ì • í¬ì¸íŠ¸! ---\n",
    "        result_image_object = inpainting_client.inpaint(\n",
    "            control_image=image_bytes,\n",
    "            control_mask=mask_bytes,\n",
    "            prompt=prompt\n",
    "        )\n",
    "        \n",
    "        # 3. ë°±ì—”ë“œë¡œë¶€í„° ë°›ì€ PIL.Image ê°ì²´ë¥¼ ì‹¤ì œ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "        #    ë°”ì´íŠ¸ ë°ì´í„°ê°€ ì•„ë‹ˆë¯€ë¡œ .save() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "        result_path = \"final_result.png\"\n",
    "        result_image_object.save(result_path)\n",
    "            \n",
    "        print(f\"   - API ì‘ë‹µ (ì„±ê³µ): ìµœì¢… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ -> '{result_path}'\")\n",
    "        return result_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   - API í˜¸ì¶œ ì˜¤ë¥˜: {e}\")\n",
    "        return f\"Inpaint API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650244ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain.tools import tool\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1529afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"model\",\n",
    "    api_key=\"EMPTY\",\n",
    "    base_url=VLLM_BASE_URL,\n",
    "    max_tokens=4096,\n",
    "    extra_body={\n",
    "        \"chat_template_kwargs\": {\"enable_thinking\": False}\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11edbf09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Okay, the user said \"hello\". I need to respond appropriately. Let me think.\\n\\nFirst, I should acknowledge their greeting. A simple \"Hello!\" would be good. Then, maybe ask how I can help them. But the user might not have a specific question yet. So, I should keep it friendly and open-ended.\\n\\nWait, in previous interactions, the assistant might have a standard response. Let me check. Oh, right, the standard is to say \"Hello! How can I assist you today?\" or something similar.\\n\\nBut maybe the user is just testing if the chatbot is working. So, a warm and helpful response is key. I should make sure to be polite and offer assistance. Let me phrase it: \"Hello! How can I assist you today?\" That\\'s straightforward and invites the user to ask their question. I don\\'t need to add anything else unless the user responds with a follow-up. So the response should be concise and friendly.\\n</think>\\n\\nHello! How can I assist you today? ğŸ˜Š', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 210, 'prompt_tokens': 11, 'total_tokens': 221, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'model', 'system_fingerprint': None, 'id': 'chatcmpl-6f8944f4bd484477967e0f51c288f44e', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--513c1c82-64c7-4c00-bb9f-add9a2012b4b-0', usage_metadata={'input_tokens': 11, 'output_tokens': 210, 'total_tokens': 221, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf3a3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.agents import create_tool_calling_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "# í”„ë¡¬í”„íŠ¸ëŠ” ì—ì´ì „íŠ¸ì—ê²Œ ëª¨ë¸ì´ ìˆ˜í–‰í•  ì‘ì—…ì„ ì„¤ëª…í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. (ë„êµ¬ì˜ ì´ë¦„ê³¼ ì—­í• ì„ ì…ë ¥)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. \"\n",
    "            \"Make sure to use the `search_news` tool for searching keyword related news.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tools = [detect_object, segment_object, inpaint_image]\n",
    "agent = create_tool_calling_agent(chat, tools=tools, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc8a417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "548caab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ì—ì´ì „íŠ¸ ì‘ì—… ì‹œì‘! =====\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `detect_object` with `{'image_path': 'dog.jpg', 'object_name': 'ê°•ì•„ì§€'}`\n",
      "responded: Okay, let me break this down. The user wants to change the dog in the image 'dog.jpg' into a dog wearing a spacesuit. So first, I need to detect the dog in the image. The tool for that is detect_object. The parameters required are image_path and object_name. The image path is given as 'dog.jpg', and the object to detect is 'ê°•ì•„ì§€' (which is Korean for dog). So I'll call detect_object with those parameters.\n",
      "\n",
      "Next step is to take the bounding box from the detect_object result and use segment_object to create a mask. The segment_object needs the image_path and the bounding_box_json. The image path is still 'dog.jpg', and the bounding box will come from the previous step's output.\n",
      "\n",
      "Then, using inpaint_image, I need to replace the masked area with a spacesuit dog. The parameters here are image_path, mask_path, and prompt. The prompt should be 'ìš°ì£¼ë³µ ì…ì€ ê°•ì•„ì§€' which translates to 'dog in a spacesuit'. The mask_path is the output from segment_object, and the image_path is the original 'dog.jpg'.\n",
      "\n",
      "Wait, but the user said the input image is 'dog.jpg', so the original image is the same for all steps. Let me make sure I'm following the steps correctly. First detect the object, then segment it to get the mask, then inpaint using the mask and the prompt. The order seems right.\n",
      "\n",
      "So first, I need to call detect_object with image_path 'dog.jpg' and object_name 'ê°•ì•„ì§€'. Then take the returned bounding box, pass it to segment_object to get the mask. Then use that mask and the prompt to inpaint. The final output should be the modified image path. The user wants the final result file path, so after inpaint_image is called, the response should be the path to the new image.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m--- 1. [ì‹¤ì œ API í˜¸ì¶œ] ê°ì²´ íƒì§€ ì‹¤í–‰: ê°•ì•„ì§€ ---\n",
      "\u001b[36;1m\u001b[1;3m{\"detections\":[{\"boxes\":[[144.72750854492188,33.6844482421875,440.606201171875,360.53790283203125]],\"scores\":[0.6146344542503357],\"labels\":[\"á„€á…¡á†¼á„‹á…¡á„Œá…µ\"]}]}\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `segment_object` with `{'image_path': 'dog.jpg', 'bounding_box_json': '[144.72750854492188, 33.6844482421875, 440.606201171875, 360.53790283203125]'}`\n",
      "responded: Okay, let's see. The user wants to replace the dog in the image with a dog wearing a spacesuit. So far, I called detect_object and got the bounding box for the dog. The response was a JSON with a detection that has a box [144.72750854492188, 33.6844482421875, 440.606201171875, 360.53790283203125]. \n",
      "\n",
      "Now, the next step is to use segment_object with the image path and the bounding box. The segment_object function needs the image_path and the bounding_box_json. The image path is still 'dog.jpg', and the bounding box from the detection is in the format of a list of coordinates. But the tool expects the bounding_box_json as a string. So I need to convert the detected box into a JSON string. Let me check the format.\n",
      "\n",
      "The detection response has \"boxes\": [[x1, y1, x2, y2]], so the first box is [144.7275..., 33.6844..., 440.6062..., 360.5379...]. The segment_object function's parameter is bounding_box_json, which should be a string. So I need to format this as a JSON object. The correct way is to take the first element of the boxes array and convert it into a JSON string. So the bounding_box_json should be \"[144.72750854492188, 33.6844482421875, 440.606201171875, 360.53790283203125]\".\n",
      "\n",
      "Wait, but the tool's parameters say \"bounding_box_json\" is a string. So the input should be a string that's a valid JSON array of four numbers. So the correct argument would be the string representation of that array. So in the function call, the bounding_box_json should be the string version of the box. So I need to make sure that the value is a string like \"[144.7275..., 33.6844..., 440.6062..., 360.5379...]\" but as a string.\n",
      "\n",
      "So for the next tool call, I should pass image_path: 'dog.jpg' and bounding_box_json: \"[144.72750854492188, 33.6844482421875, 440.606201171875, 360.53790283203125]\". Let me confirm the exact values from the response. The first box in the detections is [144.72750854492188, 33.6844482421875, 440.606201171875, 360.53790283203125]. So the string should be exactly that array as a string.\n",
      "\n",
      "Once that's done, the segment_object function will return the mask path. Then, the next step is to use inpaint_image with the original image, the mask path, and the prompt \"ìš°ì£¼ë³µ ì…ì€ ê°•ì•„ì§€\". The final output should be the path of the modified image. So the next step is to call segment_object with the correct parameters.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "--- 2. [ë„êµ¬ ì‹¤í–‰] segment_object ---\n",
      "   - ì…ë ¥: image_path='dog.jpg', bounding_box_json='[144.72750854492188, 33.6844482421875, 440.606201171875, 360.53790283203125]'\n",
      "   - API ìš”ì²­: box=[144, 33, 440, 360] ë¥¼ /segment/box ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³´ëƒ…ë‹ˆë‹¤.\n",
      "   - API ì‘ë‹µ (ì„±ê³µ): ë§ˆìŠ¤í¬ íŒŒì¼ ì €ì¥ ì™„ë£Œ -> 'mask_result.png'\n",
      "\u001b[33;1m\u001b[1;3mmask_result.png\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `inpaint_image` with `{'image_path': 'dog.jpg', 'mask_path': 'mask_result.png', 'prompt': 'ìš°ì£¼ë³µ ì…ì€ ê°•ì•„ì§€'}`\n",
      "responded: Okay, let me go through the steps again to make sure I didn't miss anything. The user wants to replace the dog in 'dog.jpg' with a dog in a spacesuit. \n",
      "\n",
      "First, I used detect_object to find the dog's bounding box. The response gave me the coordinates. Then, I called segment_object with those coordinates to create a mask. The tool returned 'mask_result.png' as the mask path. \n",
      "\n",
      "Now, the next step is to use inpaint_image. The parameters needed are image_path, mask_path, and prompt. The image_path is the original 'dog.jpg', the mask_path is 'mask_result.png', and the prompt should be 'ìš°ì£¼ë³µ ì…ì€ ê°•ì•„ì§€' which means 'dog in a spacesuit'. \n",
      "\n",
      "I need to make sure that all the parameters are correctly set. The image_path is correct, the mask_path is the output from the previous step, and the prompt is the user's request. \n",
      "\n",
      "So, the final function call should be to inpaint_image with these three parameters. The expected output is the path to the edited image. Once that's done, the user will get the final image path.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m\n",
      "--- 3. [ë„êµ¬ ì‹¤í–‰] inpaint_image ---\n",
      "   - ì…ë ¥: image_path='dog.jpg', mask_path='mask_result.png', prompt='ìš°ì£¼ë³µ ì…ì€ ê°•ì•„ì§€'\n",
      "   - API ìš”ì²­: prompt='ìš°ì£¼ë³µ ì…ì€ ê°•ì•„ì§€' ë¥¼ /generate/inpaint ì—”ë“œí¬ì¸íŠ¸ë¡œ ë³´ëƒ…ë‹ˆë‹¤.\n",
      "   - API ì‘ë‹µ (ì„±ê³µ): ìµœì¢… ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ -> 'final_result.png'\n",
      "\u001b[38;5;200m\u001b[1;3mfinal_result.png\u001b[0m\u001b[32;1m\u001b[1;3mOkay, let me recap what's been done so far. The user wanted to replace the dog in 'dog.jpg' with a dog wearing a spacesuit.\n",
      "\n",
      "First, I used detect_object to find the dog's position. The response gave a bounding box. Then, segment_object created a mask from that box, resulting in 'mask_result.png'. Finally, inpaint_image used the original image, the mask, and the prompt to generate the edited image. The tool response was 'final_result.png', which is the output path.\n",
      "\n",
      "So, the final step is to inform the user that the process is complete and provide the path to the final image. Since the tool returned 'final_result.png', that's the correct file path to return.\n",
      "\n",
      "\n",
      "ìµœì¢… ê²°ê³¼ë¬¼ íŒŒì¼ ê²½ë¡œ: final_result.png\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "===== ì—ì´ì „íŠ¸ ì‘ì—… ì™„ë£Œ! =====\n",
      "ìµœì¢… ê²°ê³¼:\n"
     ]
    }
   ],
   "source": [
    "user_image = \"dog.jpg\"\n",
    "user_text = \"ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ê°•ì•„ì§€ë¥¼ ìš°ì£¼ë³µ ì…ì€ ê°•ì•„ì§€ë¡œ ë°”ê¿”ì¤˜.\"\n",
    "prompt_for_agent = f\"\"\"ë‹¹ì‹ ì€ ì´ë¯¸ì§€ í¸ì§‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë‹¨ê³„ë³„ë¡œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡:\n",
    "- detect_object(image_path, object_name): ì´ë¯¸ì§€ì—ì„œ ë¬¼ì²´ì˜ ìœ„ì¹˜(ì¢Œí‘œ)ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "- segment_object(image_path, bounding_box_json): ì¢Œí‘œë¥¼ ë°›ì•„ ë§ˆìŠ¤í¬ë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "- inpaint_image(image_path, mask_path, prompt): ë§ˆìŠ¤í¬ ì˜ì—­ì„ í”„ë¡¬í”„íŠ¸ì— ë”°ë¼ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ì‘ì—… ì ˆì°¨:\n",
    "1. ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•´ì„œ 'ë¬´ì—‡ì„' ì°¾ì„ì§€ íŒŒì•…í•œ ë’¤, `detect_object`ë¥¼ í˜¸ì¶œí•˜ì„¸ìš”.\n",
    "2. `detect_object`ì˜ ê²°ê³¼(ì¢Œí‘œ)ë¥¼ `segment_object`ì— ë„˜ê²¨ì„œ ë§ˆìŠ¤í¬ë¥¼ ë§Œë“œì„¸ìš”.\n",
    "3. ì›ë³¸ ì´ë¯¸ì§€, ìƒì„±ëœ ë§ˆìŠ¤í¬, ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ ìµœì¢… ìš”êµ¬ì‚¬í•­ì„ ë‹´ì€ í”„ë¡¬í”„íŠ¸ë¥¼ `inpaint_image`ì— ë„˜ê²¨ì„œ ìµœì¢… ì´ë¯¸ì§€ë¥¼ ë§Œë“œì„¸ìš”.\n",
    "\n",
    "# ì‚¬ìš©ì ìš”ì²­ì‚¬í•­\n",
    "- ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ: '{user_image}'\n",
    "- ìš”ì²­ ë‚´ìš©: '{user_text}'\n",
    "\n",
    "ì´ì œ ìœ„ ì ˆì°¨ì— ë”°ë¼ ì‘ì—…ì„ ì‹œì‘í•˜ê³ , ìµœì¢… ê²°ê³¼ë¬¼ íŒŒì¼ ê²½ë¡œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n===== ì—ì´ì „íŠ¸ ì‘ì—… ì‹œì‘! =====\")\n",
    "\n",
    "\n",
    "result = agent_executor.invoke({\"input\": prompt_for_agent})\n",
    "\n",
    "print(\"\\n===== ì—ì´ì „íŠ¸ ì‘ì—… ì™„ë£Œ! =====\")\n",
    "print(\"ìµœì¢… ê²°ê³¼:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906c157f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
